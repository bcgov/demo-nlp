{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d0cb4c-a1fa-4736-9053-59d32cb6456c",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our stuff to the path\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# other stuff\n",
    "from autocorrect import Speller\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# import our stuff\n",
    "from importlib import reload\n",
    "from src import connect, preprocess, synthetic, model, matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b63c3-7bb0-40b2-88b9-e22ca1ded814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# info to gain access to database, IDIR restricted \n",
    "CRED_PATH = '../credentials.txt'\n",
    "\n",
    "# where model is stored. requires credentials.txt for full path \n",
    "MODEL_BASE_PATH = 'Model/Q22'\n",
    "\n",
    "# which tables to access\n",
    "RESPONSE_TABLE = 'dbo.AQ22ANCES'\n",
    "RESULTS_TABLE = 'AQ22ANCES_RESULTS'\n",
    "MASTER_RESULTS_TABLE = 'dbo.AQ22ANCES_RESULTS_Done'\n",
    "\n",
    "# which column to use/create \n",
    "RESPONSE_COLUMN = 'aq22_cleaned'\n",
    "OUTPUT_COLUMNS = 'q22ances_c'\n",
    "N_COLUMNS = 5\n",
    "\n",
    "# delimiter to send back with concatenated results\n",
    "DELIMITER = 'Î¼' \n",
    "\n",
    "# threshold for accepting as a flagged category\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# upper and lower thresholds for flagging as a possible category\n",
    "TENTATIVE_UPPER = 0.75\n",
    "TENTATIVE_LOWER = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7a9af-9d08-4c72-8e54-75a1e86fccec",
   "metadata": {},
   "source": [
    "## Full Pipeline\n",
    "\n",
    "1. Read in data from database (IDIR restricted)\n",
    "2. Load in model (from LAN)\n",
    "3. Preprocess data (code stored on GitHub)\n",
    "4. Create predictions based on word scores\n",
    "5. Re-incorprate multiple-choice responses\n",
    "7. Pull final values that were actually used after the end of all modeling/QA/manual work was done from database\n",
    "   \n",
    "   * note that this whole workflow is required because of the way the data is stored in the database - no longer have access to the model results, only the final post model and manual coding results only for this question.\n",
    "     \n",
    "9. Create metrics to compare:\n",
    "\n",
    "    * how much the model added\n",
    "    * how much it differed from the final outputs that were used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded3ff3-b997-494a-b887-01f77e391859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FULL MODEL PIPELINE\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#    READ IN DATA    #\n",
    "#                    #\n",
    "######################\n",
    "print(f'Reading in data... ', end = '')\n",
    "\n",
    "connection = connect.create_connection(CRED_PATH)\n",
    "df_open = connect.fetch_table(RESPONSE_TABLE, connection)\n",
    "# responses that have been done already\n",
    "#df_done = connect.fetch_table(MASTER_RESULTS_TABLE, connection)\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#    LOAD MODEL      #\n",
    "#                    #\n",
    "######################\n",
    "print('Loading model from file... ', end = '')\n",
    "\n",
    "clf, code_df_long = model.load_model(CRED_PATH, MODEL_BASE_PATH)\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#  PREPROCESS DATA   #\n",
    "#                    #\n",
    "######################\n",
    "print('Preprocessing data... ', end = '')\n",
    "\n",
    "# get new ids\n",
    "#completed_ids = df_done.id.unique()\n",
    "df_filtered = df_open.copy()#[~df_open.id.isin(completed_ids)].reset_index(drop=True)\n",
    "\n",
    "# reshape dataframe\n",
    "df = preprocess.reshape_df(df_filtered)\n",
    "\n",
    "# clean column\n",
    "# first create the speller\n",
    "code_list = code_df_long.description.values\n",
    "\n",
    "# create a spell checker\n",
    "spell = Speller()\n",
    "\n",
    "# get a list of all words that are directly in the code words \n",
    "all_words = []\n",
    "for word in code_list:\n",
    "    words = re.split(r'\\sand\\s|[,;()/\\r\\n\\s]+', word)\n",
    "    for x in words:\n",
    "        if len(x) > 0:\n",
    "            all_words.append(x)\n",
    "            \n",
    "# add additional words that are not inaccurate \n",
    "words = [\n",
    "    'Inuit',\n",
    "    'Wsanec',\n",
    "    'Tongo',\n",
    "    'Levant',\n",
    "    'Berber',\n",
    "    'Guinea-Bissau',\n",
    "    'Guinea',\n",
    "    'Bissau',\n",
    "    'Goan',\n",
    "    'Dessie',\n",
    "    'Chilean',\n",
    "    'Burundi',\n",
    "    'Burmese',\n",
    "    'Hongkonger',\n",
    "    'Konger'\n",
    "]\n",
    "\n",
    "for word in all_words + words:\n",
    "\n",
    "    for x in [word, word.upper(), word.lower()]:\n",
    "        if x in spell.nlp_data:\n",
    "            continue\n",
    "            \n",
    "        spell.nlp_data[word] = 100\n",
    "        spell.nlp_data[word.upper()] = 100\n",
    "        spell.nlp_data[word.lower()] = 100\n",
    "\n",
    "\n",
    "# spellcheck responses \n",
    "df[RESPONSE_COLUMN] = df.aq22ances.apply(lambda x: preprocess.correct_spelling(x, spell=spell))\n",
    "df[RESPONSE_COLUMN] = df[RESPONSE_COLUMN].astype(str)\n",
    "\n",
    "# translate, only those that start with &\n",
    "#df.loc[df.aq22ances.str[0] == '&', RESPONSE_COLUMN] = df[df.aq22ances.str[0] == '&'][RESPONSE_COLUMN].apply(lambda x: matching.get_translation(x, skip=False)[0])\n",
    "print('Done.')\n",
    "\n",
    "print('Creating model inputs... ', end = '')\n",
    "# inputs to model\n",
    "headers = list(preprocess.get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "input_df = preprocess.get_scores_from_df(df, RESPONSE_COLUMN, code_df_long, headers=headers)\n",
    "print('Done.')\n",
    "\n",
    "# having memory issues so convert to chunks\n",
    "chunk_size = 1000\n",
    "chunks_input = [input_df.iloc[i:i+chunk_size] for i in range(0, len(input_df), chunk_size)]\n",
    "processed_chunks_input = []\n",
    "n_chunks = len(chunks_input)\n",
    "print_str = 'Converting chunks... '\n",
    "print(print_str, end = '\\r')\n",
    "for idx, chunk in enumerate(chunks_input):\n",
    "    processed_chunk = preprocess.convert_input(chunk)\n",
    "    processed_chunks_input.append(processed_chunk)\n",
    "    print_str_2 = print_str + f'{idx+1:02}/{n_chunks}'\n",
    "    print(print_str_2, end = '\\r')\n",
    "input_df = pd.concat(processed_chunks_input, ignore_index=True)\n",
    "print(print_str_2 + ' Done.')\n",
    "\n",
    "# outputs of model (for selected responses to be included)\n",
    "print('Creating selected response outputs... ', end = '')\n",
    "output_df = preprocess.get_outputs_wide(df, RESPONSE_COLUMN, code_df_long, OUTPUT_COLUMNS, N_COLUMNS)\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#     RUN MODEL      #\n",
    "#                    #\n",
    "######################\n",
    "print('Running model and extracting results... ')\n",
    "results_df = model.produce_results(\n",
    "    df, input_df, output_df, \n",
    "    clf,\n",
    "    OUTPUT_COLUMNS,\n",
    "    N_COLUMNS,\n",
    "    question = 'Q22',\n",
    "    threshold=THRESHOLD,\n",
    "    tentative_lower = TENTATIVE_LOWER,\n",
    "    tentative_upper = TENTATIVE_UPPER,\n",
    "    delimiter = DELIMITER\n",
    ")\n",
    "print('\\nDone.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "# GET FINAL RESULTS  #\n",
    "#                    #\n",
    "######################\n",
    "print(f'Getting final results... ', end = '')\n",
    "connection = connect.create_connection(CRED_PATH)\n",
    "final_df = connect.fetch_table(MASTER_RESULTS_TABLE, connection)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd39ed-9484-4f2f-9cf1-219f4161882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic model metrics\n",
    "(\n",
    "    results_df[['id', 'match', 'original_matched', 'extra_categories', 'n_original_categories', 'n_model_categories']].astype('float')\n",
    "    .assign(added_categories = lambda x: (x['extra_categories']>0)*1)\n",
    "    .agg(\n",
    "        {\n",
    "            'id': 'count',\n",
    "            'match': 'sum',\n",
    "            'original_matched': 'mean',\n",
    "            'extra_categories': 'mean',\n",
    "            'n_model_categories': 'mean',\n",
    "            'added_categories': 'sum'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a150620-7391-437a-a379-d553d1e72ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[~pd.isnull(results_df.tentative_categories)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d145cb3-1886-4015-85d1-021d7dc57fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the set of final model categories to the final set of final categories... \n",
    "def make_set(row):\n",
    "    n_max = 5\n",
    "    full_set = set()\n",
    "    for ii in range(1,n_max+1):\n",
    "        col_name = f'q22ances_c{ii:02d}'\n",
    "        val = row[col_name]\n",
    "        if val is not None:\n",
    "            full_set.add(val)\n",
    "    return full_set\n",
    "\n",
    "results_df['model_set'] = results_df.apply(make_set, axis=1)\n",
    "final_df['final_set'] = final_df.apply(make_set, axis=1)\n",
    "\n",
    "final_df['final_comment'] = final_df['aq22ances']\n",
    "results_df['model_comment'] = results_df['aq22ances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594852b-6a3d-412e-877d-7cf5af030d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df[['id', 'final_set', 'final_comment']].merge(results_df[['id', 'model_set', 'model_comment']], how='left', on='id')\n",
    "test_df['matches'] = test_df.apply(lambda x: x.final_set == x.model_set, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf8c2b-a352-4f4e-948c-23a1ed7cdf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total:   {test_df.shape[0]:,}')\n",
    "print(f'Matched: {test_df.matches.sum():,}')\n",
    "print(f'Percent: {test_df.matches.sum()/test_df.shape[0]:0.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be49d0f-0888-4795-b36e-709a06659115",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[~test_df.matches][['final_comment', 'final_set', 'model_set']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1d6d-7a57-4450-84d2-58d127c6b054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "be45c03807294ac819668e5fda9b4af6d371c7a940204f04d201690045a7cc59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
