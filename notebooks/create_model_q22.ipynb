{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e4659d-840d-4ea1-835f-ba8278e2452d",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under he License.\n",
    "the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dc5f4-fa17-4889-953b-91fb80993c15",
   "metadata": {},
   "source": [
    "## Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our stuff to the path\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# other stuff\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autocorrect import Speller\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import our stuff\n",
    "from importlib import reload\n",
    "from src import connect, preprocess, synthetic, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b63c3-7bb0-40b2-88b9-e22ca1ded814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# info to gain access to database, IDIR restricted \n",
    "CRED_PATH = '../credentials.txt'\n",
    "\n",
    "# where model is stored. requires credentials.txt for full path \n",
    "MODEL_BASE_PATH = 'Model/Q22'\n",
    "\n",
    "# which tables to access\n",
    "RESPONSE_TABLE = 'dbo.AQ22ANCES'\n",
    "CODE_TABLE = 'dbo.AQ22ANCES_Codes'\n",
    "CLOSED_TABLE = 'dbo.Q22ANCESMultiResponse'\n",
    "RESULTS_TABLE = 'dbo.AQ22ANCES_RESULTS'\n",
    "\n",
    "# which column to use/create \n",
    "RESPONSE_COLUMN = 'aq22_cleaned'\n",
    "OUTPUT_COLUMNS = 'q22ances_c'\n",
    "N_COLUMNS = 5\n",
    "\n",
    "# delimiter to send back with concatenated results\n",
    "DELIMITER = 'Î¼' \n",
    "\n",
    "# amount of synthetic data to produce\n",
    "N_PER_CATEGORY = 10_000\n",
    "N_SYNTHETIC_MIXED = 200_000\n",
    "\n",
    "# threshold for accepting as a flagged category\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# upper and lower thresholds for flagging as a possible category\n",
    "TENTATIVE_UPPER = 0.75\n",
    "TENTATIVE_LOWER = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54f611-761b-4767-ae3f-bb63535496e8",
   "metadata": {},
   "source": [
    "## Read from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b9eac-0f68-42c4-8a58-c58a8afa02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all data required to build model\n",
    "connection = connect.create_connection(CRED_PATH)\n",
    "\n",
    "# actual responses\n",
    "df_open = connect.fetch_table(RESPONSE_TABLE, connection)\n",
    "\n",
    "# codes to match\n",
    "code_df = connect.fetch_table(CODE_TABLE, connection)\n",
    "\n",
    "# closed respones (for multi response frequencies)\n",
    "df_closed = connect.fetch_table(CLOSED_TABLE, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8d536-a8dc-4dee-b9bc-0c171ffe1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the dataframe\n",
    "df_reshaped = preprocess.reshape_df(df_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only cycle 1 for now \n",
    "df_reshaped[df_reshaped.cycle == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a154b-e1d4-4357-992d-eda35defff6a",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "* Use only cycle 1 for training.\n",
    "* Use the cleaned column.\n",
    "* Correct spelling where possible (takes longer time to run).\n",
    "* Create input and output tables for model (input table takes a while to produce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded3ff3-b997-494a-b887-01f77e391859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training purposes, open responses should only be those from cycle 1\n",
    "df = df_reshaped[df_reshaped.cycle == 1].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d4b39-bced-4f02-959f-2a28c8c32128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get long form table of codes: step 1: turn countries into rows\n",
    "code_df_long_tmp = preprocess.get_long_form_codes(code_df)\n",
    "code_df_long_tmp.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: add additional rows for each country (nationalities, other spellings, etc.)\n",
    "code_df_long = preprocess.get_long_form_codes_q22(code_df_long_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f1a6f-6801-4ae3-a5cb-6e181ba3be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833513b-8021-4f7d-872e-b10360ac5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = code_df_long.description.values\n",
    "\n",
    "# create a spell checker\n",
    "spell = Speller()\n",
    "\n",
    "# get a list of all words that are directly in the code words \n",
    "all_words = []\n",
    "for word in code_list:\n",
    "    words = re.split(r'\\sand\\s|[,;()/\\r\\n\\s]+', word)\n",
    "    for x in words:\n",
    "        if len(x) > 0:\n",
    "            all_words.append(x)\n",
    "            \n",
    "# add additional words that are not inaccurate \n",
    "words = [\n",
    "    'Inuit',\n",
    "    'Wsanec',\n",
    "    'Tongo',\n",
    "    'Levant',\n",
    "    'Berber',\n",
    "    'Guinea-Bissau',\n",
    "    'Goan',\n",
    "    'Dessie',\n",
    "    'Chilean',\n",
    "    'Burundi',\n",
    "    'Burmese,\n",
    "    'Hongkonger'\n",
    "]\n",
    "\n",
    "for word in all_words + words:\n",
    "\n",
    "    for x in [word, word.upper(), word.lower()]:\n",
    "        if x in spell.nlp_data:\n",
    "            continue\n",
    "            \n",
    "        spell.nlp_data[word] = 100\n",
    "        spell.nlp_data[word.upper()] = 100\n",
    "        spell.nlp_data[word.lower()] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e1ef4-4986-4a12-a669-01d42f0a8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spellcheck responses \n",
    "df[RESPONSE_COLUMN] = df.aq22ances.apply(lambda x: preprocess.correct_spelling(x, spell=spell))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb91f3-8a3b-424e-a02b-f5fcc712e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62736b10-818c-4d04-bf77-e38c4b0b881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a training dataset for the model \n",
    "# first part of dataset: actual data\n",
    "code_df_long['code'] = code_df_long['code'].astype(str)\n",
    "df[RESPONSE_COLUMN] = df[RESPONSE_COLUMN].astype(str)\n",
    "\n",
    "# INPUTS TO MODEL\n",
    "headers = list(preprocess.get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "\n",
    "input_df_tmp = preprocess.get_scores_from_df(df, RESPONSE_COLUMN, code_df_long, headers=headers)\n",
    "input_columns = list(input_df_tmp.columns)\n",
    "input_df = preprocess.convert_input(input_df_tmp)\n",
    "display(input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403176f-edc3-41fc-874d-ac205109ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUTS OF MODEL\n",
    "# converts the coded columns into wide form 1/0 binary responses for every option \n",
    "output_df = preprocess.get_outputs_wide(df, RESPONSE_COLUMN, code_df_long, OUTPUT_COLUMNS, N_COLUMNS)\n",
    "output_df.head()\n",
    "output_columns = list(output_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac22f57-dc8a-4750-b811-39aea4b2e5b0",
   "metadata": {},
   "source": [
    "## Create Synthetic Data\n",
    "\n",
    "* To augment our training data, produce synthetic data from the available phrases in the code list. \n",
    "* Both singular phrases and multi-response phrases are produced.\n",
    "* The multi-response phrases are randomly generated according to weights associated with the non-written responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112e577-94b1-4f67-82b1-2488dc37ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01465766-e2cc-4573-a710-b0283536714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data\n",
    "# this section will create synthetic data that matches a single category based on available phrases \n",
    "extra_input_df, extra_output_df = synthetic.create_single_phrase_synthetic(\n",
    "    output_df, \n",
    "    input_columns,\n",
    "    output_columns,\n",
    "    code_df_long,\n",
    "    n_per_category = N_PER_CATEGORY,\n",
    "    use_given = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5508d1-ad22-4c7b-99df-b8f6330783d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data\n",
    "# this section will create synthetic data that matches multiple categories\n",
    "mixed_input_df, mixed_output_df = synthetic.create_multi_phrase_synthetic(\n",
    "    output_df,\n",
    "    df_closed,\n",
    "    input_columns,\n",
    "    output_columns,\n",
    "    code_df_long,\n",
    "    N_SYNTHETIC_MIXED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea257f-fd7a-440f-9d67-d200180bb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3424bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96de156",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunks_extra_input = [extra_input_df.iloc[i:i+chunk_size] for i in range(0, len(extra_input_df), chunk_size)]\n",
    "chunks_mixed_input = [mixed_input_df.iloc[i:i+chunk_size] for i in range(0, len(mixed_input_df), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2347da2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_chunks_extra_input = []\n",
    "n_chunks = len(chunks_extra_input)\n",
    "for idx, chunk in enumerate(chunks_extra_input):\n",
    "    try:\n",
    "        processed_chunk = preprocess.convert_input(chunk)\n",
    "        processed_chunks_extra_input.append(processed_chunk)\n",
    "        print(f\"Chunk {idx+1:02}/{n_chunks} processed successfully for extra_input!\", end = '\\r')\n",
    "    except Exception as e:\n",
    "        print(f\"Error in chunk {idx} for extra_input: {e}\")\n",
    "\n",
    "extra_input_df = pd.concat(processed_chunks_extra_input, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a6754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_chunks_mixed_input = []\n",
    "n_chunks = len(chunks_mixed_input)\n",
    "for idx, chunk in enumerate(chunks_mixed_input):\n",
    "    try:\n",
    "        processed_chunk = preprocess.convert_input(chunk)\n",
    "        processed_chunks_mixed_input.append(processed_chunk)\n",
    "        print(f\"Chunk {idx+1:02}/{n_chunks} processed successfully for mixed_input!\", end='\\r')\n",
    "    except Exception as e:\n",
    "        print(f\"Error in chunk {idx} for mixed_input: {e}\")\n",
    "\n",
    "mixed_input_df = pd.concat(processed_chunks_mixed_input, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06945ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate data\n",
    "final_input_df = pd.concat(\n",
    "    [\n",
    "        #input_df, \n",
    "        extra_input_df, \n",
    "        mixed_input_df\n",
    "    ], \n",
    "    ignore_index=True).drop('response', axis=1).astype(float)\n",
    "final_output_df = pd.concat(\n",
    "    [\n",
    "        #output_df, \n",
    "        extra_output_df, \n",
    "        mixed_output_df\n",
    "    ]\n",
    "    , \n",
    "    ignore_index=True).drop('response', axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70571cd-a98e-401e-b4ce-d11958e91470",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038441c6-474d-4169-8084-fba05887b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99a1d8-f918-46bf-ba04-0e827332e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75215ceb-7244-4da5-8761-9fab7a56b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ed2d4-01bc-4243-9885-e486e86e7633",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "To deal with the fact we have many possible categorical outputs, use a simple random forest model that will handle multiple outputs better than other models.\n",
    "\n",
    "* After training, save model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd8dd6-5bf3-4c6d-ac6b-081bd3950eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f9711-5f8a-43df-acdc-fa828a8bb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "clf = model.create_model(final_input_df, final_output_df, n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ce80e-8f72-484f-937d-1d573195f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(CRED_PATH, MODEL_BASE_PATH, clf, code_df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a3f42-0c71-4cb4-9eeb-10f8a9871bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, code_df_long = model.load_model(CRED_PATH, MODEL_BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5b474-281d-4312-80b4-bedea2ed5ee1",
   "metadata": {},
   "source": [
    "## Produce Model Results\n",
    "\n",
    "* Look at some results by hand to see if it makes sense\n",
    "* Create results for entire hand-coded dataset\n",
    "* Send results back to databse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b02e4-286c-4e6d-a625-9f26c89000aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'uk'\n",
    "model.list_classes(sentence, code_df_long, clf, truncate_inputs=True, spellcheck=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dbbe0-2290-4a14-b77f-2b3e8a0aa254",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83291026-be4d-4ff0-a5b7-5854e1eba0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = model.produce_results(\n",
    "    df, input_df, output_df, \n",
    "    clf,\n",
    "    OUTPUT_COLUMNS,\n",
    "    N_COLUMNS,\n",
    "    question = 'Q22',\n",
    "    threshold=THRESHOLD,\n",
    "    tentative_lower = TENTATIVE_LOWER,\n",
    "    tentative_upper = TENTATIVE_UPPER,\n",
    "    delimiter = DELIMITER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc51ce-eb1c-415c-a31d-bbe3947be9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save back to database\n",
    "engine = connect.create_connection(CRED_PATH, sqlalchemy=True)\n",
    "\n",
    "# for initial save of cycle 1, always replace. any subsequent inputs should be appended\n",
    "connect.save_table(results_df, RESULTS_TABLE, engine, how='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f8fe2-37b5-44de-a6aa-2183bb2aa2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
