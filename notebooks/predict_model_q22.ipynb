{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d0cb4c-a1fa-4736-9053-59d32cb6456c",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our stuff to the path\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# other stuff\n",
    "from autocorrect import Speller\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# import our stuff\n",
    "from importlib import reload\n",
    "from src import connect, preprocess, synthetic, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79b63c3-7bb0-40b2-88b9-e22ca1ded814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# info to gain access to database, IDIR restricted \n",
    "CRED_PATH = '../credentials.txt'\n",
    "\n",
    "# where model is stored. requires credentials.txt for full path \n",
    "MODEL_BASE_PATH = 'Model/Q22'\n",
    "\n",
    "# which tables to access\n",
    "RESPONSE_TABLE = 'dbo.AQ22ANCES'\n",
    "RESULTS_TABLE = 'dbo.AQ22ANCES_RESULTS'\n",
    "MASTER_RESULTS_TABLE = 'dbo.AQ22ANCES_RESULTS'\n",
    "\n",
    "# which column to use/create \n",
    "RESPONSE_COLUMN = 'aq22_cleaned'\n",
    "OUTPUT_COLUMNS = 'q22ances_c'\n",
    "N_COLUMNS = 5\n",
    "\n",
    "# delimiter to send back with concatenated results\n",
    "DELIMITER = 'Î¼' \n",
    "\n",
    "# threshold for accepting as a flagged category\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# upper and lower thresholds for flagging as a possible category\n",
    "TENTATIVE_UPPER = 0.75\n",
    "TENTATIVE_LOWER = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7a9af-9d08-4c72-8e54-75a1e86fccec",
   "metadata": {},
   "source": [
    "## Full Model Pipeline\n",
    "\n",
    "1. Read in data from database (IDIR restricted)\n",
    "2. Load in model (from LAN)\n",
    "3. Preprocess data (code stored on GitHub)\n",
    "    \n",
    "    * Limit to new IDs\n",
    "    * Lower case and cleaned spelling where possible\n",
    "    * Turn responses into word scores (how close is each response to every word in the vocabulary code base). <br>\n",
    "    <br>\n",
    "\n",
    "4. Create predictions based on word scores\n",
    "5. Re-incorprate multiple-choice responses\n",
    "6. Add flag(s) for unusual model outputs\n",
    "    \n",
    "    * Was no category predicted\n",
    "    * Are there model outputs in an 'iffy' probability range <br>\n",
    "    <br>\n",
    "\n",
    "7. Send results back to database (IDIR restricted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded3ff3-b997-494a-b887-01f77e391859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data... "
     ]
    }
   ],
   "source": [
    "# FULL MODEL PIPELINE\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#    READ IN DATA    #\n",
    "#                    #\n",
    "######################\n",
    "print(f'Reading in data... ', end = '')\n",
    "\n",
    "connection = connect.create_connection(CRED_PATH)\n",
    "df_open = connect.fetch_table(RESPONSE_TABLE, connection)\n",
    "# responses that have been done already\n",
    "df_done = connect.fetch_table(MASTER_RESULTS_TABLE, connection)\n",
    "\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#    LOAD MODEL      #\n",
    "#                    #\n",
    "######################\n",
    "print('Loading model from file... ', end = '')\n",
    "\n",
    "clf, code_df_long = model.load_model(CRED_PATH, MODEL_BASE_PATH)\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#  PREPROCESS DATA   #\n",
    "#                    #\n",
    "######################\n",
    "print('Preprocessing data... ', end = '')\n",
    "\n",
    "# get new ids\n",
    "completed_ids = df_done.id.unique()\n",
    "df_filtered = df_open[~df_open.id.isin(completed_ids)].reset_index(drop=True)\n",
    "\n",
    "# reshape dataframe\n",
    "df = preprocess.reshape_df(df_filtered)\n",
    "\n",
    "# clean column\n",
    "# first create the speller\n",
    "code_list = code_df_long.description.values\n",
    "\n",
    "# create a spell checker\n",
    "spell = Speller()\n",
    "\n",
    "# get a list of all words that are directly in the code words \n",
    "all_words = []\n",
    "for word in code_list:\n",
    "    words = re.split(r'\\sand\\s|[,;()/\\r\\n\\s]+', word)\n",
    "    for x in words:\n",
    "        if len(x) > 0:\n",
    "            all_words.append(x)\n",
    "            \n",
    "# add additional words that are not inaccurate \n",
    "words = [\n",
    "    'Inuit',\n",
    "    'Wsanec',\n",
    "    'Tongo',\n",
    "    'Levant',\n",
    "    'Berber',\n",
    "    'Guinea-Bissau',\n",
    "    'Guinea',\n",
    "    'Bissau',\n",
    "    'Goan',\n",
    "    'Dessie',\n",
    "    'Chilean',\n",
    "    'Burundi',\n",
    "    'Burmese',\n",
    "    'Hongkonger',\n",
    "    'Konger'\n",
    "]\n",
    "\n",
    "for word in all_words + words:\n",
    "\n",
    "    for x in [word, word.upper(), word.lower()]:\n",
    "        if x in spell.nlp_data:\n",
    "            continue\n",
    "            \n",
    "        spell.nlp_data[word] = 100\n",
    "        spell.nlp_data[word.upper()] = 100\n",
    "        spell.nlp_data[word.lower()] = 100\n",
    "\n",
    "\n",
    "# spellcheck responses \n",
    "df[RESPONSE_COLUMN] = df.aq22ances.apply(lambda x: preprocess.correct_spelling(x, spell=spell))\n",
    "df[RESPONSE_COLUMN] = df[RESPONSE_COLUMN].astype(str)\n",
    "print('Done.')\n",
    "\n",
    "print('Creating model inputs... ', end = '')\n",
    "# inputs to model\n",
    "headers = list(preprocess.get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "input_df = preprocess.get_scores_from_df(df, RESPONSE_COLUMN, code_df_long, headers=headers)\n",
    "input_df = preprocess.convert_input(input_df)\n",
    "print('Done.')\n",
    "\n",
    "# outputs of model (for selected responses to be included)\n",
    "print('Creating selected response outputs... ', end = '')\n",
    "output_df = preprocess.get_outputs_wide(df, RESPONSE_COLUMN, code_df_long, OUTPUT_COLUMNS, N_COLUMNS)\n",
    "print('Done.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#     RUN MODEL      #\n",
    "#                    #\n",
    "######################\n",
    "print('Running model and extracting results... ')\n",
    "results_df = model.produce_results(\n",
    "    df, input_df, output_df, \n",
    "    clf,\n",
    "    OUTPUT_COLUMNS,\n",
    "    N_COLUMNS,\n",
    "    question = 'Q22',\n",
    "    threshold=THRESHOLD,\n",
    "    tentative_lower = TENTATIVE_LOWER,\n",
    "    tentative_upper = TENTATIVE_UPPER,\n",
    "    delimiter = DELIMITER\n",
    ")\n",
    "print('\\nDone.')\n",
    "\n",
    "######################\n",
    "#                    #\n",
    "#    SAVE RESULTS    #\n",
    "#                    #\n",
    "######################\n",
    "print(f'Sending results to table {RESULTS_TABLE}... ', end = '')\n",
    "# save back to database\n",
    "engine = connect.create_connection(CRED_PATH, sqlalchemy=True)\n",
    "connect.save_table(results_df, RESULTS_TABLE, engine, how='replace') # be careful when appending that you aren't doubling data\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73a39a-456d-4f4e-905f-95d70559e387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
