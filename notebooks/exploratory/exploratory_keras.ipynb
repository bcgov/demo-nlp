{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6408ada6-d2f1-4ae0-8c9b-903352312eb8",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system stuff\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "# connection stuff\n",
    "import pyodbc\n",
    "\n",
    "# standard stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nlp stuff\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# ml stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import keras\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3b9eac-0f68-42c4-8a58-c58a8afa02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_path = '../../credentials.txt'\n",
    "\n",
    "connection_str = ''\n",
    "with open(cred_path) as infile:\n",
    "    for line in infile:\n",
    "        connection_str += line.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b866985a-980f-461e-80da-9a1ecad26782",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect(connection_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059f32b4-e91e-45a8-a4e5-8cd0063f9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JDUAN\\AppData\\Local\\Temp\\ipykernel_24412\\887684786.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n",
      "C:\\Users\\JDUAN\\AppData\\Local\\Temp\\ipykernel_24412\\887684786.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  code_df = pd.read_sql(\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE WHERE Cycle=1', \n",
    "    connection\n",
    ")\n",
    "\n",
    "code_df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE_Codes', \n",
    "    connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4732a2c-b55c-4a2f-bac3-2414c1cd4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data headers \n",
    "def clean_headers(df):\n",
    "    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85cfe03f-b655-4ade-8ba3-2c85d1bc8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headers(df)\n",
    "clean_headers(code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b73ddec-8670-4cee-81c2-74ebb547d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q32race</th>\n",
       "      <th>aq32race</th>\n",
       "      <th>aq32race_cleaned</th>\n",
       "      <th>coding_comment</th>\n",
       "      <th>q32race_c01</th>\n",
       "      <th>q32race_c02</th>\n",
       "      <th>q32race_c03</th>\n",
       "      <th>q32race_c04</th>\n",
       "      <th>q32race_c05</th>\n",
       "      <th>...</th>\n",
       "      <th>q32race_c09</th>\n",
       "      <th>q32race_c10</th>\n",
       "      <th>q32race_c11</th>\n",
       "      <th>q32race_c12</th>\n",
       "      <th>q32race_c13</th>\n",
       "      <th>q32race_c14</th>\n",
       "      <th>q32race_c15</th>\n",
       "      <th>q32race_c16</th>\n",
       "      <th>cycle</th>\n",
       "      <th>aq32race_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0037231</td>\n",
       "      <td>105µ97</td>\n",
       "      <td>Second generation Canadian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>second generation canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0037247</td>\n",
       "      <td>97</td>\n",
       "      <td>Caucasion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>caucasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0037261</td>\n",
       "      <td>97</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0037282</td>\n",
       "      <td>105µ97</td>\n",
       "      <td>Brasileiro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>brasileiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0037287</td>\n",
       "      <td>97</td>\n",
       "      <td>Canadian- Spanish</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>canadian- spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id q32race                    aq32race aq32race_cleaned  \\\n",
       "0  0037231  105µ97  Second generation Canadian             None   \n",
       "1  0037247      97                   Caucasion             None   \n",
       "2  0037261      97                    Canadian             None   \n",
       "3  0037282  105µ97                  Brasileiro             None   \n",
       "4  0037287      97          Canadian- Spanish              None   \n",
       "\n",
       "  coding_comment q32race_c01 q32race_c02 q32race_c03 q32race_c04 q32race_c05  \\\n",
       "0           None         105          97        None        None        None   \n",
       "1           None          97        None        None        None        None   \n",
       "2           None          97        None        None        None        None   \n",
       "3           None         105          97        None        None        None   \n",
       "4           None          97        None        None        None        None   \n",
       "\n",
       "   ... q32race_c09 q32race_c10 q32race_c11 q32race_c12 q32race_c13  \\\n",
       "0  ...        None        None        None        None        None   \n",
       "1  ...        None        None        None        None        None   \n",
       "2  ...        None        None        None        None        None   \n",
       "3  ...        None        None        None        None        None   \n",
       "4  ...        None        None        None        None        None   \n",
       "\n",
       "  q32race_c14 q32race_c15 q32race_c16 cycle           aq32race_combined  \n",
       "0        None        None        None     1  second generation canadian  \n",
       "1        None        None        None     1                   caucasion  \n",
       "2        None        None        None     1                    canadian  \n",
       "3        None        None        None     1                  brasileiro  \n",
       "4        None        None        None     1          canadian- spanish   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a cleaned up column to use (mix of actual comment column and cleaned)\n",
    "df['aq32race_combined'] = df.apply(\n",
    "    lambda x: x.aq32race.lower() if x.aq32race_cleaned == None or x.aq32race_cleaned=='105' else x.aq32race_cleaned.lower(), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c38aad-35b0-409a-b840-e611ef37d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_description(description):\n",
    "\n",
    "    # check for NULLs\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    # split string based on comma delimiters, as well as words in brackets\n",
    "    desc_list = re.split(r'\\sand\\s|\\sor\\s|[,()\\r\\n]+', description)\n",
    "\n",
    "    # lower case, remove extra characters and remove spaces\n",
    "    desc_list = [x.lower().replace('\"', '').replace('_', '').strip(' ') for x in desc_list]\n",
    "\n",
    "    # remove descriptors that are empty\n",
    "    desc_list = [x for x in desc_list if x!='']\n",
    "\n",
    "    return desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8684e06-b2fa-4c00-931f-0ff9b766dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long form of all possible descriptors used\n",
    "\n",
    "code_dict_long = { 'code': [], 'description': [] }\n",
    "\n",
    "for idx, row in code_df.iterrows():\n",
    "    code = row.q_code\n",
    "\n",
    "    qc_desc = split_description(row.qc_desc)\n",
    "    qc_desc_notes = split_description(row.qc_desc_notes)\n",
    "    additional_notes = split_description(row.additional_notes)\n",
    "\n",
    "    all_desc = qc_desc + qc_desc_notes + additional_notes\n",
    "\n",
    "    # remove duplicates \n",
    "    all_desc = [*set(all_desc)]\n",
    "    \n",
    "    n_desc = len(all_desc)\n",
    "\n",
    "    if n_desc==0:\n",
    "        continue\n",
    "\n",
    "    # append to dictionary\n",
    "    code_dict_long['code'].extend([code]*n_desc)\n",
    "    code_dict_long['description'].extend(all_desc)\n",
    "\n",
    "code_df_long = pd.DataFrame(code_dict_long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d3487f-bf05-4391-a479-df7881219b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>105</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>105</td>\n",
       "      <td>balkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>105</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>105</td>\n",
       "      <td>australian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>105</td>\n",
       "      <td>anglo-saxon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>105</td>\n",
       "      <td>eastern european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>105</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>105</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>105</td>\n",
       "      <td>sapmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>105</td>\n",
       "      <td>western european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>105</td>\n",
       "      <td>saami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>105</td>\n",
       "      <td>white-passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>105</td>\n",
       "      <td>russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>105</td>\n",
       "      <td>prussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>105</td>\n",
       "      <td>european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>105</td>\n",
       "      <td>caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>105</td>\n",
       "      <td>scandinavian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>105</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>105</td>\n",
       "      <td>doukhobour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>105</td>\n",
       "      <td>new zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>105</td>\n",
       "      <td>slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>105</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code       description\n",
       "34  105                uk\n",
       "35  105            balkan\n",
       "36  105            french\n",
       "37  105        australian\n",
       "38  105       anglo-saxon\n",
       "39  105  eastern european\n",
       "40  105             irish\n",
       "41  105           italian\n",
       "42  105             sapmi\n",
       "43  105  western european\n",
       "44  105             saami\n",
       "45  105     white-passing\n",
       "46  105           russian\n",
       "47  105          prussian\n",
       "48  105          european\n",
       "49  105         caucasian\n",
       "50  105      scandinavian\n",
       "51  105             white\n",
       "52  105        doukhobour\n",
       "53  105       new zealand\n",
       "54  105            slavic\n",
       "55  105            german"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df_long[code_df_long.code=='105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e429e869-6416-430a-919e-1d0d6205c401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>88</td>\n",
       "      <td>i don't know/ i am unsure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                description\n",
       "157   88  i don't know/ i am unsure"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df_long[code_df_long.description.str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f221587-9f18-4334-8a52-706a80c34548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>indeterminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>afro-canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>jamaican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>nigerian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>99</td>\n",
       "      <td>none of the above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>99</td>\n",
       "      <td>prefer not to answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>99</td>\n",
       "      <td>i don't have a race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>99</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>99</td>\n",
       "      <td>absurd response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code           description\n",
       "0    10000         indeterminate\n",
       "1      101         afro-canadian\n",
       "2      101              jamaican\n",
       "3      101               african\n",
       "4      101              nigerian\n",
       "..     ...                   ...\n",
       "187     99     none of the above\n",
       "188     99  prefer not to answer\n",
       "189     99   i don't have a race\n",
       "190     99               comment\n",
       "191     99       absurd response\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "233d96e3-3e0d-4f58-ab93-8ccd385ab631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>10000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>1041</th>\n",
       "      <th>1042</th>\n",
       "      <th>1043</th>\n",
       "      <th>1044</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>90004</th>\n",
       "      <th>90005</th>\n",
       "      <th>90006</th>\n",
       "      <th>90007</th>\n",
       "      <th>90008</th>\n",
       "      <th>90009</th>\n",
       "      <th>90010</th>\n",
       "      <th>90011</th>\n",
       "      <th>97</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second generation canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caucasion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brasileiro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canadian- spanish</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>sri lankan burgher</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6627</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6628</th>\n",
       "      <td>second generation canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>english</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6631 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        response 10000 101 102 103 1041 1042 1043 1044 105  \\\n",
       "0     second generation canadian     0   0   0   0    0    0    0    0   1   \n",
       "1                      caucasion     0   0   0   0    0    0    0    0   0   \n",
       "2                       canadian     0   0   0   0    0    0    0    0   0   \n",
       "3                     brasileiro     0   0   0   0    0    0    0    0   1   \n",
       "4             canadian- spanish      0   0   0   0    0    0    0    0   0   \n",
       "...                          ...   ...  ..  ..  ..  ...  ...  ...  ...  ..   \n",
       "6626          sri lankan burgher     0   0   0   0    0    0    0    0   1   \n",
       "6627                    canadian     0   0   0   0    0    0    0    0   0   \n",
       "6628  second generation canadian     0   0   0   0    0    0    0    0   1   \n",
       "6629                     english     0   0   0   0    0    0    0    0   1   \n",
       "6630                    canadian     0   0   0   0    0    0    0    0   0   \n",
       "\n",
       "      ... 90004 90005 90006 90007 90008 90009 90010 90011 97 99  \n",
       "0     ...     0     0     0     0     0     0     0     0  1  0  \n",
       "1     ...     0     0     0     0     0     0     0     0  1  0  \n",
       "2     ...     0     0     0     0     0     0     0     0  1  0  \n",
       "3     ...     0     0     0     0     0     0     0     0  1  0  \n",
       "4     ...     0     0     0     0     0     0     0     0  1  0  \n",
       "...   ...   ...   ...   ...   ...   ...   ...   ...   ... .. ..  \n",
       "6626  ...     0     0     0     0     0     0     0     0  1  0  \n",
       "6627  ...     0     0     0     0     0     0     0     0  1  0  \n",
       "6628  ...     0     0     0     0     0     0     0     0  1  0  \n",
       "6629  ...     0     0     0     0     0     0     0     0  1  0  \n",
       "6630  ...     0     0     0     0     0     0     0     0  1  0  \n",
       "\n",
       "[6631 rows x 62 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create testing df\n",
    "# converts the coded columns into wide form 1/0 binary responses for every option \n",
    "code_list = code_df_long.code.unique()\n",
    "output_length = len(code_list)\n",
    "\n",
    "test_df = pd.DataFrame(columns = ['response'] + list(code_list))\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    response = row.aq32race_combined\n",
    "    code_vals = [0]*len(code_list)\n",
    "    for ii in range(1,17):\n",
    "        column = f'q32race_c{ii:02}'\n",
    "        possible_code = row[column]\n",
    "        if possible_code is None:\n",
    "            continue\n",
    "        else:\n",
    "            idx_option = np.where(code_list==possible_code)[0]\n",
    "            if len(idx_option)>0:\n",
    "                code_vals[idx_option[0]] = 1\n",
    "\n",
    "    tmp_df = pd.DataFrame(np.array([response] + code_vals).reshape(1, -1), columns = ['response'] + list(code_list))\n",
    "    test_df = pd.concat([test_df, tmp_df]).reset_index(drop=True)\n",
    "\n",
    "test_df.iloc[:, 1:] = test_df.iloc[:, 1:].astype(int)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95f5254-7d3a-4288-ab04-2692d6a2df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Code: 105 -- Observations: 2082\n",
      "Code: 20001 -- Observations: 2055 + 0026. Done.\n",
      "Code: 97 -- Observations: 1099 + 0982. Done.\n",
      "Code: 110 -- Observations: 254 + 1827. Done.\n",
      "Code: 1044 -- Observations: 181 + 1900. Done.\n",
      "Code: 112 -- Observations: 141 + 1940. Done.\n",
      "Code: 1041 -- Observations: 72 + 2009. Done.\n",
      "Code: 30000 -- Observations: 71 + 2010. Done.\n",
      "Code: 60000 -- Observations: 65 + 2016. Done.\n",
      "Code: 10000 -- Observations: 61 + 2020. Done.\n",
      "Code: 101 -- Observations: 52 + 2029. Done.\n",
      "Code: 106 -- Observations: 51 + 2030. Done.\n",
      "Code: 1112 -- Observations: 44 + 2037. Done.\n",
      "Code: 108 -- Observations: 44 + 2037. Done.\n",
      "Code: 40000 -- Observations: 43 + 2038. Done.\n",
      "Code: 99 -- Observations: 41 + 2040. Done.\n",
      "Code: 20000 -- Observations: 34 + 2047. Done.\n",
      "Code: 20002 -- Observations: 34 + 2047. Done.\n",
      "Code: 109 -- Observations: 28 + 2053. Done.\n",
      "Code: 102 -- Observations: 22 + 2059. Done.\n",
      "Code: 1042 -- Observations: 22 + 2059. Done.\n",
      "Code: 1111 -- Observations: 17 + 2064. Done.\n",
      "Code: 103 -- Observations: 14 + 2067. Done.\n",
      "Code: 90001 -- Observations: 12 + 2069. Done.\n",
      "Code: 90005 -- Observations: 9 + 2072. Done.\n",
      "Code: 50001 -- Observations: 9 + 2072. Done.\n",
      "Code: 20003 -- Observations: 9 + 2072. Done.\n",
      "Code: 90003 -- Observations: 9 + 2072. Done.\n",
      "Code: 80000 -- Observations: 7 + 2074. Done.\n",
      "Code: 1043 -- Observations: 6 + 2075. Done.\n",
      "Code: 88 -- Observations: 5 + 2076. Done.\n",
      "Code: 70000 -- Observations: 5 + 2076. Done.\n",
      "Code: 90004 -- Observations: 3 + 2078. Done.\n",
      "Code: 90002 -- Observations: 3 + 2078. Done.\n",
      "Code: 20004 -- Observations: 3 + 2078. Done.\n",
      "Code: 50003 -- Observations: 3 + 2078. Done.\n",
      "Code: 90006 -- Observations: 2 + 2079. Done.\n",
      "Code: 107 -- Observations: 2 + 2079. Done.\n",
      "Code: 50002 -- Observations: 2 + 2079. Done.\n",
      "Code: 50012 -- Observations: 1 + 2080. Done.\n",
      "Code: 20001 -- Observations: 1 + 2080. Done.\n",
      "Code: 10001 -- Observations: 1\n",
      "Code: Human -- Observations: 1\n",
      "Code: 50014 -- Observations: 1 + 2080. Done.\n",
      "Code: 90007 -- Observations: 1 + 2080. Done.\n",
      "Code: 90008 -- Observations: 1 + 2080. Done.\n",
      "Code: 50010 -- Observations: 1 + 2080. Done.\n",
      "Code: 50006 -- Observations: 1 + 2080. Done.\n",
      "Code: 200003 -- Observations: 1\r"
     ]
    }
   ],
   "source": [
    "# create synthetic data\n",
    "# this section will create snythetic data that matches a single category based on available phrases \n",
    "code_counts = df.q32race_c01.value_counts()\n",
    "max_counts = code_counts.values[0]\n",
    "extra_test_df = pd.DataFrame(columns = test_df.columns)\n",
    "\n",
    "for idx, val in code_counts.items():\n",
    "    print()\n",
    "    print_string = f'Code: {idx} -- Observations: {val}'\n",
    "    print(print_string, end='\\r')\n",
    "\n",
    "    # don't add any more to biggest class \n",
    "    if val == max_counts:\n",
    "        continue\n",
    "    else:\n",
    "        if idx=='Human':\n",
    "            continue\n",
    "        idx = idx.strip(' ')\n",
    "        # find all words associated with that index\n",
    "        desc_list = code_df_long[code_df_long.code==idx].description.values\n",
    "        code_vals = [0]*len(code_list)\n",
    "        code_idx = np.where(code_list==idx)[0]\n",
    "        if len(code_idx) == 0:\n",
    "            continue\n",
    "            \n",
    "        code_vals[code_idx[0]] = 1\n",
    "\n",
    "        n_more_counts = max_counts - val\n",
    "\n",
    "        # create extra responses for each category\n",
    "        for ii in range(n_more_counts):\n",
    "            print_string = f'Code: {idx} -- Observations: {val} + {ii:04}'\n",
    "            print(print_string, end='\\r')\n",
    "\n",
    "            # choose from list at random - should choose uniformly from options \n",
    "            description = random.choice(desc_list)\n",
    "            tmp_test = pd.DataFrame(np.array([response] + code_vals).reshape(1, -1), columns = test_df.columns)\n",
    "\n",
    "            tmp_test.iloc[:, 1:] = tmp_test.iloc[:, 1:].astype(int)\n",
    "\n",
    "            extra_test_df = pd.concat([extra_test_df, tmp_test])\n",
    "\n",
    "        print_string = f'Code: {idx} -- Observations: {val} + {ii:04}. Done.'\n",
    "        print(print_string, end='\\r')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b95f5b-4cd3-4ef9-a895-bb25d4ab3adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>10000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>1041</th>\n",
       "      <th>1042</th>\n",
       "      <th>1043</th>\n",
       "      <th>1044</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>90004</th>\n",
       "      <th>90005</th>\n",
       "      <th>90006</th>\n",
       "      <th>90007</th>\n",
       "      <th>90008</th>\n",
       "      <th>90009</th>\n",
       "      <th>90010</th>\n",
       "      <th>90011</th>\n",
       "      <th>97</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canadian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   response 10000 101 102 103 1041 1042 1043 1044 105  ... 90004 90005 90006  \\\n",
       "0  canadian     0   0   0   0    0    0    0    0   0  ...     0     0     0   \n",
       "0  canadian     0   0   0   0    0    0    0    0   0  ...     0     0     0   \n",
       "0  canadian     0   0   0   0    0    0    0    0   0  ...     0     0     0   \n",
       "0  canadian     0   0   0   0    0    0    0    0   0  ...     0     0     0   \n",
       "0  canadian     0   0   0   0    0    0    0    0   0  ...     0     0     0   \n",
       "\n",
       "  90007 90008 90009 90010 90011 97 99  \n",
       "0     0     0     0     0     0  0  0  \n",
       "0     0     0     0     0     0  0  0  \n",
       "0     0     0     0     0     0  0  0  \n",
       "0     0     0     0     0     0  0  0  \n",
       "0     0     0     0     0     0  0  0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cf1b5ab-e530-4f44-9c6a-2668e7440269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_copies_y = pd.concat([test_df, extra_test_df]).drop('response', axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d585157b-b66e-4a24-99c2-de7328cf1ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_with_copies_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_with_copies_x\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m, \u001b[39m4\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_with_copies_x' is not defined"
     ]
    }
   ],
   "source": [
    "train_with_copies_x.iloc[0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f985462f-55f3-451d-ba32-e21eeadebbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2268"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras playground\n",
    "test = []\n",
    "for idx, row in df.iterrows():\n",
    "    response = row.aq32race_combined\n",
    "    words = response.lower().split(' ')\n",
    "    for word in words:\n",
    "        word = word.strip(' ')\n",
    "        if word == '':\n",
    "            continue\n",
    "        if word not in test:\n",
    "            test.append(word)\n",
    "\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3809394-971c-4720-bbc5-150ecfac760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "MAX_SEQUENCE_LENGTH = 256 # actual max 216\n",
    "VOCAB_SIZE = 15000\n",
    "\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 512\n",
    "\n",
    "reserved_tokens = [\"[PAD]\", \"[UNK]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5822493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88bc9579-75c6-47c5-b326-72ab18a5ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize data\n",
    "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
    "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
    "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "        word_piece_ds.batch(1000).prefetch(2),\n",
    "        vocabulary_size=vocab_size,\n",
    "        reserved_tokens=reserved_tokens,\n",
    "    )\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eda5f86-3d03-48d7-8ff2-3c61594aa1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_copies = pd.concat([test_df, extra_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dcf8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cd4743c-e05c-44c4-8647-058103b7c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.data.Dataset.from_tensor_slices(df_with_copies['response'].values)\n",
    "Y = tf.data.Dataset.from_tensor_slices(df_with_copies.drop('response', axis=1).values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f956505-8435-4867-9edd-8c39a7c8d1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(61,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "861cba2a-0cd0-4f54-add3-42752aeff8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "715a0397-e3d7-45ea-a3c6-7737f8a7092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 61), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.zip((X, Y))\n",
    "ds = ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea5f344a-11f8-4d1d-9e49-2f1a4d53af75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'second generation canadian'\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "b'caucasion'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "b'canadian'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206e539d-d0b7-4c8b-a743-468f96bd8851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(64,) (64, 61)\n",
      "(36,) (36, 61)\n"
     ]
    }
   ],
   "source": [
    "for a, b in ds:\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1d59f2a-5732-4d41-b357-4bafe8b58308",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_word_piece(ds, VOCAB_SIZE, reserved_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2648a100-3e21-473a-81ad-ae17df796177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5327e4fa-b960-4d59-bfce-1bf08372fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anglo',\n",
       " 'hong',\n",
       " 'iranian',\n",
       " '##ic',\n",
       " '##ing',\n",
       " 'but',\n",
       " '##ed',\n",
       " '##a',\n",
       " 'canada',\n",
       " '##o']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb9d7a2-9af5-4500-95d6-a6901a08062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    lowercase=False,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bc2a8db-c96e-4dc1-801a-45ca4a713e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  tf.Tensor(b'second generation canadian', shape=(), dtype=string)\n",
      "Tokens:  tf.Tensor(\n",
      "[ 46  68 281 332  88 122  58   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0], shape=(256,), dtype=int32)\n",
      "Recovered text after detokenizing:  tf.Tensor(b'second generation canadian [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "input_sentence_ex = ds.take(1).get_single_element()[0][0]\n",
    "input_tokens_ex = tokenizer(input_sentence_ex)\n",
    "\n",
    "print(\"Sentence: \", input_sentence_ex)\n",
    "print(\"Tokens: \", input_tokens_ex)\n",
    "print(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8b25270-449d-400e-9b99-9d6bfcab5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 61), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a775630-ec0e-4c44-9a44-f71b0a66d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format dataset\n",
    "def format_dataset(sentence, label):\n",
    "    sentence = tokenizer(sentence)\n",
    "    return (sentence, label)\n",
    "\n",
    "def make_dataset(dataset):\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "154966d1-f9d7-4d21-b968-b21b51b35e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92a0c6f6-1e2a-4a63-856b-a872b2a48908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
       "array([[ 46,  68, 281, ...,   0,   0,   0],\n",
       "       [115,   0,   0, ...,   0,   0,   0],\n",
       "       [ 58,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 58,   0,   0, ...,   0,   0,   0],\n",
       "       [ 58,   0,   0, ...,   0,   0,   0],\n",
       "       [ 69,  11,  58, ...,   0,   0,   0]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1).get_single_element()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e49b61a6-b1ad-4b8b-97eb-e92efa826ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "input_ids = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")(input_ids)\n",
    "\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "outputs = keras.layers.Dense(output_length, activation=\"sigmoid\")(x)\n",
    "\n",
    "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9ba2103-c834-4b6a-b0d0-c3c6cd32e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fnet_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 128)        1952768   \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " f_net_encoder (FNetEncoder)  (None, None, 128)        132224    \n",
      "                                                                 \n",
      " f_net_encoder_1 (FNetEncode  (None, None, 128)        132224    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " f_net_encoder_2 (FNetEncode  (None, None, 128)        132224    \n",
      " r)                                                              \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 61)                7869      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,357,309\n",
      "Trainable params: 2,357,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fnet_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37fe1d7b-794f-4d60-b87a-9c497ac77d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12166739713216212592\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5836374016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9350135564655422580\n",
      "physical_device_desc: \"device: 0, name: NVIDIA RTX A2000 8GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42311f1d-5333-4956-abd5-529a6e1c1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet_classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40d5ae70-a4ed-43c9-b366-b583f91a1a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1497/1497 [==============================] - 72s 46ms/step - loss: 2.9269 - accuracy: 0.4749\n",
      "Epoch 2/3\n",
      "1497/1497 [==============================] - 69s 46ms/step - loss: 2.2011 - accuracy: 0.4184\n",
      "Epoch 3/3\n",
      "1497/1497 [==============================] - 73s 49ms/step - loss: 2.1089 - accuracy: 0.3596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8b3d32ec0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnet_classifier.fit(train_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88dc4a48-9dc6-4400-a378-a569b73839b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1497 [==============================] - 27s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "out = fnet_classifier.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b224d553-443d-4482-a0b6-58a9aa9be9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.576226  , 0.49136236, 0.23476495, ..., 0.21153957, 0.786703  ,\n",
       "        0.5846038 ],\n",
       "       [0.57925856, 0.4924781 , 0.23093706, ..., 0.21222655, 0.78635716,\n",
       "        0.5883668 ],\n",
       "       [0.5778354 , 0.49123242, 0.2312302 , ..., 0.21290135, 0.7852449 ,\n",
       "        0.58655673],\n",
       "       ...,\n",
       "       [0.5778297 , 0.4912404 , 0.23122998, ..., 0.21279384, 0.7852368 ,\n",
       "        0.5865586 ],\n",
       "       [0.5778297 , 0.4912404 , 0.23122998, ..., 0.21279384, 0.7852368 ,\n",
       "        0.5865586 ],\n",
       "       [0.5778297 , 0.4912404 , 0.23122998, ..., 0.21279384, 0.7852368 ,\n",
       "        0.5865586 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a47b0a8-31c6-417d-8f01-f584e18855d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['second generation canadian', 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head().values[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34948b36-250b-415e-ba0a-a2c2aff5e36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20000'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33cff375-8179-4967-9320-de45a944e1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256), dtype=int32, numpy=\n",
       "array([[ 58,   8,  91,   8,  28, 167, 136, 109,   9,  69,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = tokenizer(['canadian, french, afro-american'])\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bb57131-b9ce-4b04-a161-6343956f6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n"
     ]
    }
   ],
   "source": [
    "test_out = fnet_classifier.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ad2fcc7-3f72-44b6-b080-0a75bfab866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 36, 26, 56, 31, 33, 37, 39, 18, 57, 29, 28, 42, 24, 58, 40, 41,\n",
       "       43, 32,  2, 35,  5, 54,  9, 12, 10, 15,  4, 45, 11, 16, 14, 47, 22,\n",
       "       19, 44, 51,  1, 53,  7, 20, 50, 46, 23, 27, 49,  0,  3, 60, 13,  6,\n",
       "       48, 21, 17, 25, 52, 55,  8, 59, 34, 30], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(test_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0db7b06b-591f-4587-9351-5aa879771148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_classes_fnet(sentence, code_list, code_df, top_n = 10):\n",
    "\n",
    "    test_input = tokenizer([sentence])\n",
    "    test_out = fnet_classifier.predict(test_input)\n",
    "\n",
    "    predictions = test_out[0]\n",
    "    ordered_idx = np.argsort(predictions)[::-1]\n",
    "    print()\n",
    "    print(f'TOP MATCHES FOR: {sentence}')\n",
    "    print()\n",
    "    for counter, idx in enumerate(ordered_idx):\n",
    "        if counter>=top_n:\n",
    "            break\n",
    "        else:\n",
    "            prob = predictions[idx]\n",
    "            code = code_list[idx]\n",
    "            desc = code_df.loc[code_df['q_code'] == code, 'qc_desc'].values[0]\n",
    "            print(f'{prob:0.2%}')\n",
    "            print(desc)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d8d6ce9-19f4-48f7-8b5d-a82a41cebcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "\n",
      "TOP MATCHES FOR: afro-canadian\n",
      "\n",
      "99.92%\n",
      "Hawaiian\n",
      "\n",
      "97.34%\n",
      "Indigenous American, Native American\n",
      "\n",
      "79.46%\n",
      "Prefer to self-describe\n",
      "\n",
      "78.82%\n",
      "European\n",
      "\n",
      "67.29%\n",
      "Indigenous n.i.e. and n.o.s\n",
      "\n",
      "66.18%\n",
      "Australiasian and Australian\n",
      "\n",
      "64.03%\n",
      "North American\n",
      "\n",
      "63.75%\n",
      "Melanesia\n",
      "\n",
      "61.89%\n",
      "Mennonite\n",
      "\n",
      "60.36%\n",
      "Middle-Eastern\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'afro-canadian'\n",
    "list_classes_fnet(sentence, code_list, code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c826c24-23f3-4060-8d9e-bd8323a5f8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "57e60505a17d0fbe5f8f846d25956a7eb417bb10a6c84851c4e594c698fe6297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
