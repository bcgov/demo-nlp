{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6408ada6-d2f1-4ae0-8c9b-903352312eb8",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system stuff\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "# connection stuff\n",
    "import pyodbc\n",
    "\n",
    "# standard stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nlp stuff\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# ml stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b9eac-0f68-42c4-8a58-c58a8afa02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_path = '../credentials.txt'\n",
    "\n",
    "connection_str = ''\n",
    "with open(cred_path) as infile:\n",
    "    for line in infile:\n",
    "        connection_str += line.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866985a-980f-461e-80da-9a1ecad26782",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect(connection_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f32b4-e91e-45a8-a4e5-8cd0063f9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE WHERE Cycle=1', \n",
    "    connection\n",
    ")\n",
    "\n",
    "code_df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE_Codes', \n",
    "    connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732a2c-b55c-4a2f-bac3-2414c1cd4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data headers \n",
    "def clean_headers(df):\n",
    "    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfe03f-b655-4ade-8ba3-2c85d1bc8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headers(df)\n",
    "clean_headers(code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73ddec-8670-4cee-81c2-74ebb547d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a cleaned up column to use (mix of actual comment column and cleaned)\n",
    "df['aq32race_combined'] = df.apply(\n",
    "    lambda x: x.aq32race.lower() if x.aq32race_cleaned == None or x.aq32race_cleaned=='105' else x.aq32race_cleaned.lower(), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c38aad-35b0-409a-b840-e611ef37d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_description(description):\n",
    "\n",
    "    # check for NULLs\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    # split string based on comma delimiters, as well as words in brackets\n",
    "    desc_list = re.split(r'\\sand\\s|\\sor\\s|[,()\\r\\n]+', description)\n",
    "\n",
    "    # lower case, remove extra characters and remove spaces\n",
    "    desc_list = [x.lower().replace('\"', '').replace('_', '').strip(' ') for x in desc_list]\n",
    "\n",
    "    # remove descriptors that are empty\n",
    "    desc_list = [x for x in desc_list if x!='']\n",
    "\n",
    "    return desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8684e06-b2fa-4c00-931f-0ff9b766dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long form of all possible descriptors used\n",
    "\n",
    "code_dict_long = { 'code': [], 'description': [] }\n",
    "\n",
    "for idx, row in code_df.iterrows():\n",
    "    code = row.q_code\n",
    "\n",
    "    qc_desc = split_description(row.qc_desc)\n",
    "    qc_desc_notes = split_description(row.qc_desc_notes)\n",
    "    additional_notes = split_description(row.additional_notes)\n",
    "\n",
    "    all_desc = qc_desc + qc_desc_notes + additional_notes\n",
    "\n",
    "    # remove duplicates \n",
    "    all_desc = [*set(all_desc)]\n",
    "    \n",
    "    n_desc = len(all_desc)\n",
    "\n",
    "    if n_desc==0:\n",
    "        continue\n",
    "\n",
    "    # append to dictionary\n",
    "    code_dict_long['code'].extend([code]*n_desc)\n",
    "    code_dict_long['description'].extend(all_desc)\n",
    "\n",
    "code_df_long = pd.DataFrame(code_dict_long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3487f-bf05-4391-a479-df7881219b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long[code_df_long.code=='105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429e869-6416-430a-919e-1d0d6205c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long[code_df_long.description.str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f221587-9f18-4334-8a52-706a80c34548",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d96e3-3e0d-4f58-ab93-8ccd385ab631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing df\n",
    "# converts the coded columns into wide form 1/0 binary responses for every option \n",
    "code_list = code_df_long.code.unique()\n",
    "output_length = len(code_list)\n",
    "\n",
    "test_df = pd.DataFrame(columns = ['response'] + list(code_list))\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    response = row.aq32race_combined\n",
    "    code_vals = [0]*len(code_list)\n",
    "    for ii in range(1,17):\n",
    "        column = f'q32race_c{ii:02}'\n",
    "        possible_code = row[column]\n",
    "        if possible_code is None:\n",
    "            continue\n",
    "        else:\n",
    "            idx_option = np.where(code_list==possible_code)[0]\n",
    "            if len(idx_option)>0:\n",
    "                code_vals[idx_option[0]] = 1\n",
    "\n",
    "    tmp_df = pd.DataFrame(np.array([response] + code_vals).reshape(1, -1), columns = ['response'] + list(code_list))\n",
    "    test_df = pd.concat([test_df, tmp_df]).reset_index(drop=True)\n",
    "\n",
    "test_df.iloc[:, 1:] = test_df.iloc[:, 1:].astype(int)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f5254-7d3a-4288-ab04-2692d6a2df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data\n",
    "# this section will create snythetic data that matches a single category based on available phrases \n",
    "code_counts = df.q32race_c01.value_counts()\n",
    "max_counts = code_counts.values[0]\n",
    "extra_test_df = pd.DataFrame(columns = test_df.columns)\n",
    "\n",
    "for idx, val in code_counts.items():\n",
    "    print()\n",
    "    print_string = f'Code: {idx} -- Observations: {val}'\n",
    "    print(print_string, end='\\r')\n",
    "\n",
    "    # don't add any more to biggest class \n",
    "    if val == max_counts:\n",
    "        continue\n",
    "    else:\n",
    "        if idx=='Human':\n",
    "            continue\n",
    "        idx = idx.strip(' ')\n",
    "        # find all words associated with that index\n",
    "        desc_list = code_df_long[code_df_long.code==idx].description.values\n",
    "        code_vals = [0]*len(code_list)\n",
    "        code_idx = np.where(code_list==idx)[0]\n",
    "        if len(code_idx) == 0:\n",
    "            continue\n",
    "            \n",
    "        code_vals[code_idx[0]] = 1\n",
    "\n",
    "        n_more_counts = max_counts - val\n",
    "\n",
    "        # create extra responses for each category\n",
    "        for ii in range(n_more_counts):\n",
    "            print_string = f'Code: {idx} -- Observations: {val} + {ii:04}'\n",
    "            print(print_string, end='\\r')\n",
    "\n",
    "            # choose from list at random - should choose uniformly from options \n",
    "            description = random.choice(desc_list)\n",
    "            tmp_test = pd.DataFrame(np.array([response] + code_vals).reshape(1, -1), columns = test_df.columns)\n",
    "\n",
    "            tmp_test.iloc[:, 1:] = tmp_test.iloc[:, 1:].astype(int)\n",
    "\n",
    "            extra_test_df = pd.concat([extra_test_df, tmp_test])\n",
    "\n",
    "        print_string = f'Code: {idx} -- Observations: {val} + {ii:04}. Done.'\n",
    "        print(print_string, end='\\r')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b95f5b-4cd3-4ef9-a895-bb25d4ab3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1b5ab-e530-4f44-9c6a-2668e7440269",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_copies_y = pd.concat([test_df, extra_test_df]).drop('response', axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585157b-b66e-4a24-99c2-de7328cf1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_copies_x.iloc[0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985462f-55f3-451d-ba32-e21eeadebbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras playground\n",
    "test = []\n",
    "for idx, row in df.iterrows():\n",
    "    response = row.aq32race_combined\n",
    "    words = response.lower().split(' ')\n",
    "    for word in words:\n",
    "        word = word.strip(' ')\n",
    "        if word == '':\n",
    "            continue\n",
    "        if word not in test:\n",
    "            test.append(word)\n",
    "\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3809394-971c-4720-bbc5-150ecfac760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "MAX_SEQUENCE_LENGTH = 256 # actual max 216\n",
    "VOCAB_SIZE = 15000\n",
    "\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 512\n",
    "\n",
    "reserved_tokens = [\"[PAD]\", \"[UNK]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc9579-75c6-47c5-b326-72ab18a5ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize data\n",
    "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
    "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
    "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "        word_piece_ds.batch(1000).prefetch(2),\n",
    "        vocabulary_size=vocab_size,\n",
    "        reserved_tokens=reserved_tokens,\n",
    "    )\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda5f86-3d03-48d7-8ff2-3c61594aa1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_copies = pd.concat([test_df, extra_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4743c-e05c-44c4-8647-058103b7c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.data.Dataset.from_tensor_slices(df_with_copies['response'].values)\n",
    "Y = tf.data.Dataset.from_tensor_slices(df_with_copies.drop('response', axis=1).values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f956505-8435-4867-9edd-8c39a7c8d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861cba2a-0cd0-4f54-add3-42752aeff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a0397-e3d7-45ea-a3c6-7737f8a7092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.zip((X, Y))\n",
    "ds = ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f344a-11f8-4d1d-9e49-2f1a4d53af75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text_batch, label_batch in ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e539d-d0b7-4c8b-a743-468f96bd8851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a, b in ds:\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d59f2a-5732-4d41-b357-4bafe8b58308",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_word_piece(ds, VOCAB_SIZE, reserved_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648a100-3e21-473a-81ad-ae17df796177",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327e4fa-b960-4d59-bfce-1bf08372fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9d7a2-9af5-4500-95d6-a6901a08062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    lowercase=False,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2a8db-c96e-4dc1-801a-45ca4a713e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence_ex = ds.take(1).get_single_element()[0][0]\n",
    "input_tokens_ex = tokenizer(input_sentence_ex)\n",
    "\n",
    "print(\"Sentence: \", input_sentence_ex)\n",
    "print(\"Tokens: \", input_tokens_ex)\n",
    "print(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b25270-449d-400e-9b99-9d6bfcab5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a775630-ec0e-4c44-9a44-f71b0a66d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format dataset\n",
    "def format_dataset(sentence, label):\n",
    "    sentence = tokenizer(sentence)\n",
    "    return (sentence, label)\n",
    "\n",
    "def make_dataset(dataset):\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154966d1-f9d7-4d21-b968-b21b51b35e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0c6f6-1e2a-4a63-856b-a872b2a48908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.take(1).get_single_element()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b61a6-b1ad-4b8b-97eb-e92efa826ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "input_ids = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")(input_ids)\n",
    "\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "outputs = keras.layers.Dense(output_length, activation=\"sigmoid\")(x)\n",
    "\n",
    "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba2103-c834-4b6a-b0d0-c3c6cd32e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe1d7b-794f-4d60-b87a-9c497ac77d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42311f1d-5333-4956-abd5-529a6e1c1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet_classifier.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5ae70-a4ed-43c9-b366-b583f91a1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet_classifier.fit(train_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc4a48-9dc6-4400-a378-a569b73839b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fnet_classifier.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224d553-443d-4482-a0b6-58a9aa9be9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47b0a8-31c6-417d-8f01-f584e18855d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head().values[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34948b36-250b-415e-ba0a-a2c2aff5e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cff375-8179-4967-9320-de45a944e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tokenizer(['canadian, french, afro-american'])\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb57131-b9ce-4b04-a161-6343956f6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = fnet_classifier.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2fcc7-3f72-44b6-b080-0a75bfab866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(test_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7b06b-591f-4587-9351-5aa879771148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_classes_fnet(sentence, code_list, code_df, top_n = 10):\n",
    "\n",
    "    test_input = tokenizer([sentence])\n",
    "    test_out = fnet_classifier.predict(test_input)\n",
    "\n",
    "    predictions = test_out[0]\n",
    "    ordered_idx = np.argsort(predictions)[::-1]\n",
    "    print()\n",
    "    print(f'TOP MATCHES FOR: {sentence}')\n",
    "    print()\n",
    "    for counter, idx in enumerate(ordered_idx):\n",
    "        if counter>=top_n:\n",
    "            break\n",
    "        else:\n",
    "            prob = predictions[idx]\n",
    "            code = code_list[idx]\n",
    "            desc = code_df.loc[code_df['q_code'] == code, 'qc_desc'].values[0]\n",
    "            print(f'{prob:0.2%}')\n",
    "            print(desc)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d6ce9-19f4-48f7-8b5d-a82a41cebcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'afro-canadian'\n",
    "list_classes_fnet(sentence, code_list, code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c826c24-23f3-4060-8d9e-bd8323a5f8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
