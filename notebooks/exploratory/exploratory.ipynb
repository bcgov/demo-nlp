{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9293f1b3-9edf-4e71-8478-d0e42e9cefe0",
   "metadata": {},
   "source": [
    "Copyright 2023 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at \n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c48dd5-971d-4078-b759-f0fe83ba6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system stuff\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "# connection stuff\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "\n",
    "# standard stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# nlp stuff\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# ml stuff\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f661c-05d7-40e4-895e-5e0342afcec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 'afro-canadian'\n",
    "test = 'canadian'\n",
    "\n",
    "print(fuzz.ratio(match, test))\n",
    "print(fuzz.partial_ratio(match, test))\n",
    "print(fuzz.token_sort_ratio(match, test))\n",
    "print(fuzz.token_set_ratio(match, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b9eac-0f68-42c4-8a58-c58a8afa02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_path = '../credentials.txt'\n",
    "\n",
    "connection_str = ''\n",
    "with open(cred_path) as infile:\n",
    "    for line in infile:\n",
    "        connection_str += line.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866985a-980f-461e-80da-9a1ecad26782",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect(connection_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f32b4-e91e-45a8-a4e5-8cd0063f9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "# Actual open responses\n",
    "df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE WHERE Cycle=1', \n",
    "    connection\n",
    ")\n",
    "\n",
    "# Codes to match to\n",
    "code_df = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE_Codes', \n",
    "    connection\n",
    ")\n",
    "\n",
    "# Closed responses to get which multi response answers are most frequent\n",
    "df_closed = pd.read_sql(\n",
    "    'SELECT * FROM dbo.Q32RACEMultiResponse', \n",
    "    connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732a2c-b55c-4a2f-bac3-2414c1cd4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data headers \n",
    "def clean_headers(df):\n",
    "    df.columns = [x.lower().replace(' ','_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfe03f-b655-4ade-8ba3-2c85d1bc8512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_headers(df)\n",
    "clean_headers(code_df)\n",
    "clean_headers(df_closed)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73ddec-8670-4cee-81c2-74ebb547d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a cleaned up column to use (mix of actual comment column and cleaned)\n",
    "df['aq32race_combined'] = df.apply(\n",
    "    lambda x: x.aq32race.lower() if x.aq32race_cleaned == None or x.aq32race_cleaned=='105' else x.aq32race_cleaned.lower(), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e3d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c38aad-35b0-409a-b840-e611ef37d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_description(description):\n",
    "\n",
    "    # check for NULLs\n",
    "    if description is None:\n",
    "        return []\n",
    "        \n",
    "    # split string based on comma delimiters, as well as words in brackets\n",
    "    desc_list = re.split(r'\\sand\\s|\\sor\\s|[,()\\r\\n]+', description)\n",
    "\n",
    "    # lower case, remove extra characters and remove spaces\n",
    "    desc_list = [x.lower().replace('\"', '').replace('_', '').strip(' ') for x in desc_list]\n",
    "\n",
    "    # remove descriptors that are empty\n",
    "    desc_list = [x for x in desc_list if x!='']\n",
    "\n",
    "    return desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8684e06-b2fa-4c00-931f-0ff9b766dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long form of all possible descriptors used\n",
    "\n",
    "code_dict_long = { 'code': [], 'description': [] }\n",
    "\n",
    "for idx, row in code_df.iterrows():\n",
    "    code = row.q_code\n",
    "\n",
    "    qc_desc = split_description(row.qc_desc)\n",
    "    qc_desc_notes = split_description(row.qc_desc_notes)\n",
    "    additional_notes = split_description(row.additional_notes)\n",
    "\n",
    "    all_desc = qc_desc + qc_desc_notes + additional_notes\n",
    "\n",
    "    # remove duplicates \n",
    "    all_desc = [*set(all_desc)]\n",
    "    \n",
    "    n_desc = len(all_desc)\n",
    "\n",
    "    if n_desc==0:\n",
    "        continue\n",
    "\n",
    "    # append to dictionary\n",
    "    code_dict_long['code'].extend([code]*n_desc)\n",
    "    code_dict_long['description'].extend(all_desc)\n",
    "\n",
    "code_df_long = pd.DataFrame(code_dict_long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3487f-bf05-4391-a479-df7881219b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long[code_df_long.code=='105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429e869-6416-430a-919e-1d0d6205c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long[code_df_long.description.str.contains('/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f221587-9f18-4334-8a52-706a80c34548",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long.groupby('description').count().reset_index().sort_values(by='code', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc21a16-fd60-46de-a6aa-5a39060b8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df_long[code_df_long.description=='comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb0fed-5942-4c01-93b6-e36883c6dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response ='canadian'\n",
    "response = response.lower()\n",
    "\n",
    "tmp = code_df_long.copy()\n",
    "tmp['ratio'] = code_df_long.description.apply(lambda x: fuzz.ratio(x, response))\n",
    "tmp['partial'] = code_df_long.description.apply(lambda x: fuzz.partial_ratio(x, response))\n",
    "tmp['sort'] = code_df_long.description.apply(lambda x: fuzz.token_sort_ratio(x, response))\n",
    "tmp['set'] = code_df_long.description.apply(lambda x: fuzz.token_set_ratio(x, response))\n",
    "tmp['id'] = code_df_long.code + '_' + code_df_long.description\n",
    "\n",
    "#tmp = pd.melt(tmp, id_vars = ['description'], value_vars=['ratio', 'partial', 'sort', 'set'])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f42a89-540d-4757-8f66-5f21c251caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(response, code_df_long, as_df = False):\n",
    "    \n",
    "    response = response.lower()\n",
    "\n",
    "    tmp = code_df_long.copy()\n",
    "    tmp['ratio'] = code_df_long.description.apply(lambda x: fuzz.ratio(x, response))\n",
    "    tmp['partial'] = code_df_long.description.apply(lambda x: fuzz.partial_ratio(x, response))\n",
    "    tmp['sort'] = code_df_long.description.apply(lambda x: fuzz.token_sort_ratio(x, response))\n",
    "    tmp['set'] = code_df_long.description.apply(lambda x: fuzz.token_set_ratio(x, response))\n",
    "    tmp['id'] = code_df_long.code + '_' + code_df_long.description\n",
    "    \n",
    "    tmp = pd.melt(tmp, id_vars = ['id'], value_vars=['ratio', 'partial', 'sort', 'set'])\n",
    "    \n",
    "    tmp['col_id'] = tmp.id + '_' + tmp.variable\n",
    "    #tmp = pd.pivot_table(tmp, columns=['description', 'variable'], values=['value']).reset_index(drop=True)\n",
    "\n",
    "    #tmp.columns = ['_'.join(col) for col in tmp.columns]\n",
    "    #tmp = tmp.rename_axis(None, axis=1)\n",
    "    #cols = tmp.columns\n",
    "    #tmp['response'] = response\n",
    "    #tmp = tmp[['response'] + list(cols)]\n",
    "\n",
    "    tmp = tmp[['col_id', 'value']]\n",
    "    \n",
    "    if as_df:\n",
    "        return tmp\n",
    "    else:\n",
    "        return tmp.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9bbd8-f8e5-43c3-8c7e-f4a960a55c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_scores('canadian', code_df_long)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d3fde-d1cc-4a99-9494-9cc449414545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "df.iloc[0:10, :].aq32race_combined.apply(lambda x: get_scores(x, code_df_long, as_df=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f62bb3-9a90-4355-9a0c-45ad93a5c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2de76-9b10-446e-98ff-e94f633f61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores('Canadian', code_df_long, as_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a04fb4-56cd-4d13-bb84-1861f1d66dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = df.iloc[0:10,:].aq32race_combined.apply(lambda x: get_scores(x, code_df_long, as_df=False))\n",
    "headers = list(get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "bb.columns = headers\n",
    "bb['response'] = df.iloc[0:10,:].aq32race_combined\n",
    "new_cols = ['response'] + headers\n",
    "bb = bb[new_cols]\n",
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403176f-edc3-41fc-874d-ac205109ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "train_df = df.aq32race_combined.apply(lambda x: get_scores(x, code_df_long, as_df=False))\n",
    "# get headers for input data \n",
    "headers = list(get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "train_df.columns = headers\n",
    "train_df['response'] = df.aq32race_combined\n",
    "train_df = train_df[['response'] + headers]\n",
    "display(train_df.head())\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b9cce-e8f3-49cf-a414-4f90abd65b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d96e3-3e0d-4f58-ab93-8ccd385ab631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing df\n",
    "# converts the coded columns into wide form 1/0 binary responses for every option \n",
    "code_list = code_df_long.code.unique()\n",
    "output_length = len(code_list)\n",
    "\n",
    "test_df = pd.DataFrame(columns = ['response'] + list(code_list))\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    response = row.aq32race_combined\n",
    "    code_vals = [0]*len(code_list)\n",
    "    for ii in range(1,17):\n",
    "        column = f'q32race_c{ii:02}'\n",
    "        possible_code = row[column]\n",
    "        if possible_code is None:\n",
    "            continue\n",
    "        else:\n",
    "            idx_option = np.where(code_list==possible_code)[0]\n",
    "            if len(idx_option)>0:\n",
    "                code_vals[idx_option[0]] = 1\n",
    "\n",
    "    tmp_df = pd.DataFrame(np.array([response] + code_vals).reshape(1, -1), columns = ['response'] + list(code_list))\n",
    "    test_df = pd.concat([test_df, tmp_df]).reset_index(drop=True)\n",
    "\n",
    "test_df.iloc[:, 1:] = test_df.iloc[:, 1:].astype(int)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1381db-da7e-4db1-8e63-ef5a3d40fccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.drop('response', axis=1).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaadd07-72c4-4411-87a7-ae9fb7c9aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f89c2-c755-428f-a434-e269af399eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f82cca-80c3-4de9-b139-f6adef1b6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_df.columns[1:]:\n",
    "    if item not in headers:\n",
    "        print(item)\n",
    "\n",
    "print('-')\n",
    "for item in headers:\n",
    "    if item not in train_df.columns[1:]:\n",
    "        print(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f5254-7d3a-4288-ab04-2692d6a2df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data\n",
    "# this section will create snythetic data that matches a single category based on available phrases \n",
    "code_counts = test_df.drop('response', axis=1).sum().sort_values(ascending=False)\n",
    "n_codes = len(code_counts)\n",
    "max_counts = code_counts.values[0]\n",
    "extra_test_df = pd.DataFrame(columns = test_df.columns)\n",
    "extra_train_df = pd.DataFrame(columns = train_df.columns)\n",
    "\n",
    "for idx, val in code_counts.items():\n",
    "    print()\n",
    "    print_string = f'Code: {idx} -- Observations: {val}'\n",
    "    print(print_string, end='\\r')\n",
    "\n",
    "    # don't add any more to biggest class \n",
    "    if val == max_counts:\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        if idx=='Human':\n",
    "            continue\n",
    "        idx = idx.strip(' ')\n",
    "        \n",
    "        # find all words associated with that index\n",
    "        desc_list = code_df_long[code_df_long.code==idx].description.values\n",
    "        code_vals = [0]*len(code_list)\n",
    "\n",
    "        # locate index of this code in code list \n",
    "        code_idx = np.where(code_list==idx)[0]\n",
    "        \n",
    "        if len(code_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        n_more_counts = max_counts - val\n",
    "\n",
    "        # randomly select synthetic data\n",
    "        random_df = pd.DataFrame(columns = ['response'], data = random.choices(desc_list, k=n_more_counts))\n",
    "\n",
    "        # create outputs\n",
    "        code_vals = np.zeros((n_more_counts, n_codes))\n",
    "        code_vals[:, code_idx] = 1\n",
    "        output_df = pd.DataFrame(columns = list(code_list), data= code_vals).astype(int)\n",
    "        output_df = random_df.merge(output_df, left_index=True, right_index=True)\n",
    "\n",
    "        # create inputs\n",
    "        input_df = random_df.response.apply(lambda x: get_scores(x, code_df_long, as_df=False))\n",
    "        input_df.columns = headers\n",
    "        input_df['response'] = random_df.response\n",
    "        input_df = input_df[['response'] + headers]\n",
    "\n",
    "        # append to extra synthetic df\n",
    "        extra_test_df = pd.concat([extra_test_df, output_df]).reset_index(drop=True)\n",
    "        extra_train_df = pd.concat([extra_train_df, input_df]).reset_index(drop=True)\n",
    "\n",
    "        print_string = f'Code: {idx} -- Observations: {val} + {n_more_counts}. Done.'\n",
    "        print(print_string, end='\\r')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b650f7-2c8c-4a0c-ab2a-6cebf7184446",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b95f5b-4cd3-4ef9-a895-bb25d4ab3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc075e2d-ffb5-4fc0-bfed-7077fbaf471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a37f3-97a5-42cf-908f-ee142d3f1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddcd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract existing combinations from test_df\n",
    "code_columns = test_df.iloc[:, 1:]\n",
    "multi_response_freq_test = test_df[code_columns.sum(axis=1) > 1].drop('response', axis=1).apply(lambda x: tuple(x.index[x == 1]), axis=1)\n",
    "multi_response_freq_test = multi_response_freq_test.value_counts().reset_index()\n",
    "multi_response_freq_test.columns = ['combination', 'frequency']\n",
    "\n",
    "# Extract combinations from df_closed\n",
    "df_closed['combination'] = df_closed['q32race'].apply(lambda x: tuple(x.split('µ')))\n",
    "multi_response_freq_closed = df_closed['combination'].value_counts().reset_index()\n",
    "multi_response_freq_closed.columns = ['combination', 'frequency']\n",
    "\n",
    "# Merge the frequency distributions\n",
    "multi_response_freq = pd.concat([multi_response_freq_test, multi_response_freq_closed])\n",
    "multi_response_freq = multi_response_freq.groupby('combination').sum().reset_index()\n",
    "\n",
    "# Normalize frequency for probability\n",
    "multi_response_freq['frequency'] /= multi_response_freq['frequency'].sum()\n",
    "\n",
    "# Initialize dataframes\n",
    "mixed_test_df = pd.DataFrame(columns=test_df.columns)\n",
    "mixed_train_df = pd.DataFrame(columns=train_df.columns)\n",
    "\n",
    "# Define parameters\n",
    "n_mixed = 50_000\n",
    "\n",
    "# Iterate to create mixed synthetic data\n",
    "for jj in range(n_mixed):\n",
    "    pct_done = int(100*(jj+1)/n_mixed)\n",
    "    print_str = f'{jj+1:05}/{n_mixed}' + '  |' + '-'*pct_done + '>' + ' '*(100-pct_done-1) + '|'\n",
    "    print(print_str, end='\\r')\n",
    "    # Choose a random combination based on frequency\n",
    "    combination = np.random.choice(multi_response_freq['combination'], p=multi_response_freq['frequency'])\n",
    "    code_vals = [0] * len(code_list)\n",
    "    phrase_list = []\n",
    "\n",
    "    for code in combination:\n",
    "        code_idx = np.where(code_list == code)[0]\n",
    "        if len(code_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        code_vals[code_idx[0]] = 1\n",
    "        desc_list = code_df_long[code_df_long.code == code].description.values\n",
    "        random_code_phrase = random.choice(desc_list)\n",
    "        phrase_list.append(random_code_phrase)\n",
    "\n",
    "    phrase = ' '.join(phrase_list)\n",
    "    mixed_test_df.loc[len(mixed_test_df)] = [phrase] + code_vals\n",
    "\n",
    "# Convert categories to int\n",
    "mixed_test_df[mixed_test_df.columns[1:]] = mixed_test_df.iloc[:, 1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75cdd2-a480-45da-8b02-db608fa6cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training values using existing get_scores function\n",
    "start = time.time()\n",
    "mixed_train_df = mixed_test_df.response.apply(lambda x: get_scores(x, code_df_long, as_df=False))\n",
    "mixed_train_df.columns = headers\n",
    "mixed_train_df['response'] = mixed_test_df.response\n",
    "mixed_train_df = mixed_train_df[['response'] + headers]\n",
    "\n",
    "end = time.time()\n",
    "print((end - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19443ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_response_freq_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_response_freq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06945ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with existing data\n",
    "final_train_data = pd.concat([train_df, extra_train_df, mixed_train_df], ignore_index=True).drop('response', axis=1).astype(int)\n",
    "final_test_data = pd.concat([test_df, extra_test_df, mixed_test_df], ignore_index=True).drop('response', axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaadcd8-3f03-448f-b045-c4d1fd79e1aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585157b-b66e-4a24-99c2-de7328cf1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53565ff-24c9-4ce4-889e-616d2a9dc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98585405-91ff-40cc-b208-269c193ffc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f9711-5f8a-43df-acdc-fa828a8bb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state = 0, verbose=1).fit(final_train_data, final_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731d6cd-27a0-4c59-a483-8ad03dc17b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_classes(sentence, code_list, code_df, code_df_long, top_n = 10, min_pct = 0.05):\n",
    "\n",
    "    test_input = get_scores(sentence, code_df_long).drop('response', axis=1)\n",
    "    test_out = clf.predict_proba(test_input)\n",
    "    for idx, item in enumerate(test_out):\n",
    "        if item.shape[1] == 1:\n",
    "            test_out[idx] = np.hstack((test_out[idx], 0*test_out[idx]))\n",
    "\n",
    "    test_out = [x[:, 1] for x in test_out]\n",
    "    test_out = np.array(test_out).T\n",
    "\n",
    "    predictions = test_out[0]\n",
    "    ordered_idx = np.argsort(predictions)[::-1]\n",
    "    print()\n",
    "    print(f'TOP MATCHES FOR: {sentence}')\n",
    "    print()\n",
    "    for counter, idx in enumerate(ordered_idx):\n",
    "        if counter>=top_n:\n",
    "            break\n",
    "        else:\n",
    "            prob = predictions[idx]\n",
    "\n",
    "            if prob < min_pct:\n",
    "                break\n",
    "                \n",
    "            code = code_list[idx]\n",
    "            desc = code_df.loc[code_df['q_code'] == code, 'qc_desc'].values[0]\n",
    "            print(f'{prob:0.2%}')\n",
    "            print(desc)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# typo autocorrection packages\n",
    "#from symspellpy import SymSpell\n",
    "from autocorrect import Speller\n",
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff44af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use autocorrect pacakage to correct typos\n",
    "def correct_spelling(sentence):\n",
    "    spell = Speller()\n",
    "    corrected_sentence = spell(sentence)\n",
    "    return corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a881dd4-0147-4ad4-b070-5dabd003c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_from_df(response_df, response_column, code_df_long, headers=None):\n",
    "    if headers is None:\n",
    "        headers = list(get_scores('test', code_df_long, as_df = True).col_id.values)\n",
    "    else:\n",
    "        # only want the non 'response' columns from an input list of headers\n",
    "        if headers[0] == 'response':\n",
    "            headers = headers[1:]\n",
    "\n",
    "    df = response_df[response_column].apply(lambda x: get_scores(x, code_df_long, as_df=False))\n",
    "    df.columns = headers\n",
    "    df['response'] = response_df[response_column]\n",
    "    df = df[['response'] + headers]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80c67e-0dd3-42a0-a7bf-efa5fa301e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores_from_df(pd.DataFrame({'response': [sentence]}), 'response', code_df_long, headers=final_train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b02e4-286c-4e6d-a625-9f26c89000aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'canadien, americn, britsh'\n",
    "corrected_sentence = correct_spelling(sentence)\n",
    "list_classes(corrected_sentence, code_list, code_df, code_df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try using textblob to autocorrect typos\n",
    "sentence = \"Blanche canadienne\"\n",
    "corrected_sentence = str(TextBlob(sentence).correct())\n",
    "list_classes(corrected_sentence, code_list, code_df, code_df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22889188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try self-defining dictionary for correct label names\n",
    "with open('custom_dictionary.txt', 'w', encoding='utf-8') as file:\n",
    "    for category in code_df_long['description']:\n",
    "        file.write(f\"{category} 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "sym_spell.load_dictionary('custom_dictionary.txt', term_index=0, count_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee89b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Canadian, white, scot/Irish back ground'\n",
    "corrected_sentence = sym_spell.lookup_compound(sentence, max_edit_distance=2)[0].term\n",
    "list_classes(corrected_sentence, code_list, code_df, code_df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use raw data to test the model\n",
    "df_validation = pd.read_sql(\n",
    "    'SELECT * FROM dbo.AQ32RACE_TEST WHERE Cycle=1', \n",
    "    connection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91665e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_classes_code(sentence, code_list, code_df, code_df_long, top_n=10, min_pct=0.05):\n",
    "    results = {}\n",
    "    test_input = get_scores(sentence, code_df_long).drop('response', axis=1)\n",
    "    test_out = clf.predict_proba(test_input)\n",
    "    for idx, item in enumerate(test_out):\n",
    "        if item.shape[1] == 1:\n",
    "            test_out[idx] = np.hstack((test_out[idx], 0 * test_out[idx]))\n",
    "\n",
    "    test_out = [x[:, 1] for x in test_out]\n",
    "    test_out = np.array(test_out).T\n",
    "\n",
    "    predictions = test_out[0]\n",
    "    ordered_idx = np.argsort(predictions)[::-1]\n",
    "\n",
    "    for counter, idx in enumerate(ordered_idx):\n",
    "        if counter >= top_n:\n",
    "            break\n",
    "        else:\n",
    "            prob = predictions[idx]\n",
    "\n",
    "            if prob < min_pct:\n",
    "                break\n",
    "\n",
    "            code = code_list[idx]\n",
    "            desc = code_df.loc[code_df['q_code'] == code, 'q_code'].values[0] # Changing it to code instead of description\n",
    "            results[desc] = prob * 100  # Storing the result as a percentage\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11608285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a score threshold\n",
    "score_threshold = 50\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "column_names = ['ID'] + ['Q32RACE_C' + str(i).zfill(2) for i in range(1, 17)]\n",
    "results_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Iterate through df_validation\n",
    "for index, row in df_validation.iterrows():\n",
    "    sentence = row['AQ32RACE']\n",
    "    corrected_sentence = sym_spell.lookup_compound(sentence, max_edit_distance=2)[0].term\n",
    "    categories = list_classes_code(corrected_sentence, code_list, code_df, code_df_long)\n",
    "    \n",
    "    # Filter by score and append to results\n",
    "    filtered_categories = [cat for cat, score in categories.items() if score > score_threshold]\n",
    "    if filtered_categories:\n",
    "        result_row = [row['ID']] + filtered_categories + [None] * (16 - len(filtered_categories))\n",
    "        results_df.loc[len(results_df)] = result_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e88a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the ID column\n",
    "combined_df = pd.merge(results_df, df, on='ID', suffixes=('_results', '_df'))\n",
    "\n",
    "# Initialize a DataFrame to store differences\n",
    "differences = pd.DataFrame()\n",
    "\n",
    "# Iterate through the columns and compare\n",
    "for i in range(1, 17):\n",
    "    col_name = f'Q32RACE_C{i:02d}'\n",
    "    differences[col_name] = combined_df[col_name + '_results'] != combined_df[col_name + '_df']\n",
    "\n",
    "# Optional: Filter to rows with differences\n",
    "differences['ID'] = combined_df['ID']\n",
    "differences = differences[differences.any(axis=1)]\n",
    "\n",
    "# The differences DataFrame now contains a True/False value for each comparison, with True indicating a difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_count = (differences['Q32RACE_C01'] == False).sum()\n",
    "total_count = differences['Q32RACE_C01'].count()\n",
    "\n",
    "ratio = false_count / total_count\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the results to database\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# Read the credentials from your file\n",
    "connection_str = ''\n",
    "with open(cred_path) as infile:\n",
    "    for line in infile:\n",
    "        connection_str += line.strip('\\n')\n",
    "\n",
    "# Create a URL for SQLAlchemy's engine\n",
    "params = urllib.parse.quote_plus(connection_str)\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "# Write DataFrame back to the database \n",
    "results_df.to_sql('AQ32RACE_Result', con=engine, if_exists='replace', index=False) # if_exists can be 'append' if want to add to an existing table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
